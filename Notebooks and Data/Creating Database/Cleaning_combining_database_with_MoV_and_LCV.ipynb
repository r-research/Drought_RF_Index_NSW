{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NDVI code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "NDVI_df = pd.read_csv('NDVI_Results_Cleaned_28July2022.csv', encoding = 'unicode_escape')\n",
    "NDVI_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>MYD13A3_061__1_km_monthly_EVI</th>\n",
       "      <th>MYD13A3_061__1_km_monthly_NDVI</th>\n",
       "      <th>MYD13A3_061__1_km_monthly_VI_Quality_VI_Usefulness_Description</th>\n",
       "      <th>MYD13A3_061__1_km_monthly_VI_Quality_Possible_snow/ice_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>-29.1039</td>\n",
       "      <td>147.9178</td>\n",
       "      <td>2002-07</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>Highest quality</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>-29.1039</td>\n",
       "      <td>147.9178</td>\n",
       "      <td>2002-08</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.3058</td>\n",
       "      <td>Highest quality</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>-29.1039</td>\n",
       "      <td>147.9178</td>\n",
       "      <td>2002-09</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>Highest quality</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>-29.1039</td>\n",
       "      <td>147.9178</td>\n",
       "      <td>2002-10</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.2786</td>\n",
       "      <td>Highest quality</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>-29.1039</td>\n",
       "      <td>147.9178</td>\n",
       "      <td>2002-11</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>Highest quality</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Location  Latitude  Longitude Year_Month  MYD13A3_061__1_km_monthly_EVI  \\\n",
       "0  Angledool  -29.1039   147.9178    2002-07                         0.1597   \n",
       "1  Angledool  -29.1039   147.9178    2002-08                         0.1573   \n",
       "2  Angledool  -29.1039   147.9178    2002-09                         0.1524   \n",
       "3  Angledool  -29.1039   147.9178    2002-10                         0.1503   \n",
       "4  Angledool  -29.1039   147.9178    2002-11                         0.1457   \n",
       "\n",
       "   MYD13A3_061__1_km_monthly_NDVI  \\\n",
       "0                          0.3307   \n",
       "1                          0.3058   \n",
       "2                          0.3011   \n",
       "3                          0.2786   \n",
       "4                          0.2617   \n",
       "\n",
       "  MYD13A3_061__1_km_monthly_VI_Quality_VI_Usefulness_Description  \\\n",
       "0                                    Highest quality               \n",
       "1                                    Highest quality               \n",
       "2                                    Highest quality               \n",
       "3                                    Highest quality               \n",
       "4                                    Highest quality               \n",
       "\n",
       "  MYD13A3_061__1_km_monthly_VI_Quality_Possible_snow/ice_Description  \n",
       "0                                                 No                  \n",
       "1                                                 No                  \n",
       "2                                                 No                  \n",
       "3                                                 No                  \n",
       "4                                                 No                  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDVI_df.drop(['MODIS_Tile','MYD13A3_061_Line_Y_1km','MYD13A3_061_Sample_X_1km','MYD13A3_061__1_km_monthly_VI_Quality','MYD13A3_061__1_km_monthly_VI_Quality_bitmask','MYD13A3_061__1_km_monthly_VI_Quality_MODLAND','MYD13A3_061__1_km_monthly_VI_Quality_MODLAND_Description','MYD13A3_061__1_km_monthly_VI_Quality_VI_Usefulness','MYD13A3_061__1_km_monthly_VI_Quality_Aerosol_Quantity','MYD13A3_061__1_km_monthly_VI_Quality_Aerosol_Quantity_Description','MYD13A3_061__1_km_monthly_VI_Quality_Adjacent_cloud_detected','MYD13A3_061__1_km_monthly_VI_Quality_Adjacent_cloud_detected_Description','MYD13A3_061__1_km_monthly_VI_Quality_Atmosphere_BRDF_Correction','MYD13A3_061__1_km_monthly_VI_Quality_Atmosphere_BRDF_Correction_Description','MYD13A3_061__1_km_monthly_VI_Quality_Mixed_Clouds','MYD13A3_061__1_km_monthly_VI_Quality_Mixed_Clouds_Description','MYD13A3_061__1_km_monthly_VI_Quality_Land/Water_Mask','MYD13A3_061__1_km_monthly_VI_Quality_Land/Water_Mask_Description','MYD13A3_061__1_km_monthly_VI_Quality_Possible_snow/ice','MYD13A3_061__1_km_monthly_VI_Quality_Possible_shadow','MYD13A3_061__1_km_monthly_VI_Quality_Possible_shadow_Description'], axis = 1, inplace = True)\n",
    "NDVI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>MYD13A3_061__1_km_monthly_NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-07</td>\n",
       "      <td>0.3307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-08</td>\n",
       "      <td>0.3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-09</td>\n",
       "      <td>0.3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-10</td>\n",
       "      <td>0.2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-11</td>\n",
       "      <td>0.2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19675</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-02</td>\n",
       "      <td>0.2327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19676</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-03</td>\n",
       "      <td>0.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19677</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>0.3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19678</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-05</td>\n",
       "      <td>0.4106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19679</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-06</td>\n",
       "      <td>0.4471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Location Year_Month  MYD13A3_061__1_km_monthly_NDVI\n",
       "0      Angledool    2002-07                          0.3307\n",
       "1      Angledool    2002-08                          0.3058\n",
       "2      Angledool    2002-09                          0.3011\n",
       "3      Angledool    2002-10                          0.2786\n",
       "4      Angledool    2002-11                          0.2617\n",
       "...          ...        ...                             ...\n",
       "19675  Wilcannia    2022-02                          0.2327\n",
       "19676  Wilcannia    2022-03                          0.2363\n",
       "19677  Wilcannia    2022-04                          0.3151\n",
       "19678  Wilcannia    2022-05                          0.4106\n",
       "19679  Wilcannia    2022-06                          0.4471\n",
       "\n",
       "[19680 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDVI_1km_df = NDVI_df.drop(['Latitude','Longitude','MYD13A3_061__1_km_monthly_EVI','MYD13A3_061__1_km_monthly_VI_Quality_VI_Usefulness_Description','MYD13A3_061__1_km_monthly_VI_Quality_Possible_snow/ice_Description'],axis = 1)\n",
    "NDVI_1km_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>MYD13A3_061__1_km_monthly_EVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-07</td>\n",
       "      <td>0.1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-08</td>\n",
       "      <td>0.1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-09</td>\n",
       "      <td>0.1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-10</td>\n",
       "      <td>0.1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angledool</td>\n",
       "      <td>2002-11</td>\n",
       "      <td>0.1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19675</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-02</td>\n",
       "      <td>0.1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19676</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-03</td>\n",
       "      <td>0.1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19677</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>0.1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19678</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-05</td>\n",
       "      <td>0.2529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19679</th>\n",
       "      <td>Wilcannia</td>\n",
       "      <td>2022-06</td>\n",
       "      <td>0.2602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Location Year_Month  MYD13A3_061__1_km_monthly_EVI\n",
       "0      Angledool    2002-07                         0.1597\n",
       "1      Angledool    2002-08                         0.1573\n",
       "2      Angledool    2002-09                         0.1524\n",
       "3      Angledool    2002-10                         0.1503\n",
       "4      Angledool    2002-11                         0.1457\n",
       "...          ...        ...                            ...\n",
       "19675  Wilcannia    2022-02                         0.1478\n",
       "19676  Wilcannia    2022-03                         0.1601\n",
       "19677  Wilcannia    2022-04                         0.1739\n",
       "19678  Wilcannia    2022-05                         0.2529\n",
       "19679  Wilcannia    2022-06                         0.2602\n",
       "\n",
       "[19680 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVI_1km_df = NDVI_df.drop(['Latitude','Longitude','MYD13A3_061__1_km_monthly_NDVI','MYD13A3_061__1_km_monthly_VI_Quality_VI_Usefulness_Description','MYD13A3_061__1_km_monthly_VI_Quality_Possible_snow/ice_Description'],axis = 1)\n",
    "EVI_1km_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'Drought_Impact_Database_28July2022_'\n",
    "clim_var_name = 'MYD13A3_061__1_km_monthly_EVI'\n",
    "# Read in database\n",
    "drought_db = pd.read_csv(database_name + '.csv', encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Geographic Location</th>\n",
       "      <th>Location</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Drought / No Drought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>March</td>\n",
       "      <td>2014-03</td>\n",
       "      <td>Cobar</td>\n",
       "      <td>Cobar</td>\n",
       "      <td>-31.4980</td>\n",
       "      <td>145.8383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>February</td>\n",
       "      <td>2014-02</td>\n",
       "      <td>Cobar</td>\n",
       "      <td>Cobar</td>\n",
       "      <td>-31.4980</td>\n",
       "      <td>145.8383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>January</td>\n",
       "      <td>2014-01</td>\n",
       "      <td>Cobar</td>\n",
       "      <td>Cobar</td>\n",
       "      <td>-31.4980</td>\n",
       "      <td>145.8383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>March</td>\n",
       "      <td>2014-03</td>\n",
       "      <td>Walgett</td>\n",
       "      <td>Walgett</td>\n",
       "      <td>-30.0167</td>\n",
       "      <td>148.1167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>February</td>\n",
       "      <td>2014-02</td>\n",
       "      <td>Walgett</td>\n",
       "      <td>Walgett</td>\n",
       "      <td>-30.0167</td>\n",
       "      <td>148.1167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year     Month Year_Month Geographic Location Location  Latitude  \\\n",
       "0  2014     March    2014-03               Cobar    Cobar  -31.4980   \n",
       "1  2014  February    2014-02               Cobar    Cobar  -31.4980   \n",
       "2  2014   January    2014-01               Cobar    Cobar  -31.4980   \n",
       "3  2014     March    2014-03             Walgett  Walgett  -30.0167   \n",
       "4  2014  February    2014-02             Walgett  Walgett  -30.0167   \n",
       "\n",
       "   Longitude  Drought / No Drought  \n",
       "0   145.8383                     1  \n",
       "1   145.8383                     1  \n",
       "2   145.8383                     1  \n",
       "3   148.1167                     1  \n",
       "4   148.1167                     1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drought_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For EVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining database and data tables according to Year,Month and Location. \n",
    "clim_var = []\n",
    "row = 1\n",
    "\n",
    "for row in drought_db.itertuples():\n",
    "    time = row.Year_Month\n",
    "    loca = row.Location\n",
    "    #print(row) # This was to check where it was failing\n",
    "    clim_var.append(float((NDVI_df.loc[(NDVI_df['Year_Month']== time) & (NDVI_df['Location']== loca)][clim_var_name].values)))\n",
    "\n",
    "#drought_db[EVI] = clim_var    \n",
    "\n",
    "#drought_db.to_csv('Database_Test_'+ climate_var_name + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db[clim_var_name] = clim_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db.to_csv('Database_'+ clim_var_name + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 938 entries, 0 to 937\n",
      "Data columns (total 9 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Year                           938 non-null    int64  \n",
      " 1   Month                          938 non-null    object \n",
      " 2   Year_Month                     938 non-null    object \n",
      " 3   Geographic Location            938 non-null    object \n",
      " 4   Location                       938 non-null    object \n",
      " 5   Latitude                       938 non-null    float64\n",
      " 6   Longitude                      938 non-null    float64\n",
      " 7   Drought / No Drought           938 non-null    int64  \n",
      " 8   MYD13A3_061__1_km_monthly_EVI  938 non-null    float64\n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 66.1+ KB\n"
     ]
    }
   ],
   "source": [
    "drought_db.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining database and data tables according to Year,Month and Location. \n",
    "clim_var = []\n",
    "row = 1\n",
    "\n",
    "clim_var_name_2 = 'MYD13A3_061__1_km_monthly_NDVI'\n",
    "#For NDVI\n",
    "for row in drought_db.itertuples():\n",
    "    time = row.Year_Month\n",
    "    loca = row.Location\n",
    "    # print(row)\n",
    "    clim_var.append(float((NDVI_df.loc[(NDVI_df['Year_Month']== time) & (NDVI_df['Location']== loca)][clim_var_name_2].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db[clim_var_name_2] = clim_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db.to_csv('Database_'+ clim_var_name_2 + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Image Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining database and data tables according to Year,Month and Location. \n",
    "clim_var_3 = []\n",
    "row = 1\n",
    "\n",
    "clim_var_name_3 = 'MYD13A3_061__1_km_monthly_VI_Quality_VI_Usefulness_Description'\n",
    "#For NDVI\n",
    "for row in drought_db.itertuples():\n",
    "    time = row.Year_Month\n",
    "    loca = row.Location\n",
    "    # print(row)\n",
    "    clim_var_3.append(str((NDVI_df.loc[(NDVI_df['Year_Month']== time) & (NDVI_df['Location']== loca)][clim_var_name_3].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db[clim_var_name_3] = clim_var_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db.to_csv('Database_'+ clim_var_name_3 + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for the other variables:\n",
    "Importing py files with functions made by me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Extract_AWRA_data_code_6_28July2022\n",
    "import Clean_Combine_Location_data_4\n",
    "import Combine_Database_Loc_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Location file:\n",
    "locations_df = pd.read_csv('Drought_Impact_Database_28July2022_.csv', encoding = 'unicode_escape')\n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 90: invalid start byte\n",
    "#locations_df = locations_df.drop(labels=range(13,38),axis=0)\n",
    "locations_df.columns = [c.replace(' ','_') for c in locations_df.columns]\n",
    "\n",
    "# FOR AWRA EXTRACTION\n",
    "# Creating arrays:\n",
    "dlat = locations_df['Latitude'][:]\n",
    "dlon = locations_df['Longitude'][:]\n",
    "dloc = locations_df['Location'][:]\n",
    "\n",
    "# FOR COMBINING AWRA EXCEL FILES: \n",
    "# Get locations list:\n",
    "df_prac = pd.read_csv('Drought_Impact_Database_28July2022_.csv', encoding = 'unicode_escape')\n",
    "df_prac.drop_duplicates(subset = [\"Location\"],inplace = True)\n",
    "list_of_locations = df_prac['Location'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will take instead just the file of locations, lat and longitudes. Using the NDVI file\n",
    "NDVI_loc_file_df = pd.read_csv('NDVI_Locations_28July.csv', encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PET Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar\n",
      "Saving location: Walgett\n",
      "Saving location: Coonamble\n",
      "Saving location: Warren\n",
      "Saving location: Nyngan\n",
      "Saving location: Gilgandra\n",
      "Saving location: Narrabri\n",
      "Saving location: Tamworth\n",
      "Saving location: Coonabarabran\n",
      "Saving location: Mittagong\n",
      "Saving location: Bowral\n",
      "Saving location: Bundanoon\n",
      "Saving location: Robertson\n",
      "Saving location: Moss Vale\n",
      "Saving location: Pilliga\n",
      "Saving location: Cobargo\n",
      "Saving location: Bega\n",
      "Saving location: Wentworth\n",
      "Saving location: Finley\n",
      "Saving location: Deniliquin\n",
      "Saving location: Pooncarie\n",
      "Saving location: Menindee\n",
      "Saving location: Broken Hill\n",
      "Saving location: Bredbo\n",
      "Saving location: Hay\n",
      "Saving location: Coleambally\n",
      "Saving location: Griffith\n",
      "Saving location: Wagga Wagga\n",
      "Saving location: Forbes\n",
      "Saving location: Oxley\n",
      "Saving location: Condobolin\n",
      "Saving location: Cowra\n",
      "Saving location: Blayney\n",
      "Saving location: Carcoar\n",
      "Saving location: Canowindra\n",
      "Saving location: Narromine\n",
      "Saving location: Orange\n",
      "Saving location: Bathurst\n",
      "Saving location: Dubbo\n",
      "Saving location: Mudgee\n",
      "Saving location: Gulgong\n",
      "Saving location: Gunnedah\n",
      "Saving location: Moree\n",
      "Saving location: Uralla\n",
      "Saving location: Goondiwindi\n",
      "Saving location: Tenterfield\n",
      "Saving location: Glen Innes\n",
      "Saving location: Mungindi\n",
      "Saving location: Ashford\n",
      "Saving location: Bonshaw\n",
      "Saving location: Bourke\n",
      "Saving location: Wilcannia\n",
      "Saving location: Collarenebri\n",
      "Saving location: Brewarrina\n",
      "Saving location: Angledool\n",
      "Saving location: Gongolgon\n",
      "Saving location: Tibooburra\n",
      "Saving location: Packsaddle\n",
      "Saving location: Byrock\n",
      "Saving location: Eden\n",
      "Saving location: Bemboka\n",
      "Saving location: Brogo\n",
      "Saving location: Bermagui\n",
      "Saving location: Casino\n",
      "Saving location: Bonalbo\n",
      "Saving location: Scone\n",
      "Saving location: Murrurundi\n",
      "Saving location: Singleton\n",
      "Saving location: Smithtown\n",
      "Saving location: Tocal\n",
      "Saving location: Grafton\n",
      "Saving location: Nowra\n",
      "Saving location: Ulladulla\n",
      "Saving location: Goulburn\n",
      "Saving location: Port Macquarie\n",
      "Saving location: Boggabilla\n",
      "Saving location: Taree\n",
      "Saving location: Raymond Terrace\n",
      "Saving location: Bogan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sy6sh\\Anaconda3\\envs\\Honours_2022\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:953: UserWarning: Warning: converting a masked element to nan.\n",
      "  values[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Wellington\n",
      "Saving location: Cobar \n",
      "Saving location: Dungog\n",
      "Saving location: Inglewood\n"
     ]
    }
   ],
   "source": [
    "#Extract Loc\n",
    "row = 1\n",
    "data_col_name = 'PET_Actual' #name of column\n",
    "for row in NDVI_loc_file_df.itertuples():\n",
    "    location = row.Category #dloc[row]\n",
    "    d_lat = float(row.Latitude)\n",
    "    d_lon = float(row.Longitude)\n",
    "    Extract_AWRA_data_code_6_28July2022.extract_var_from_netcdf('pet_Actual_month',location,d_lat,d_lon,data_col_name)\n",
    "\n",
    "#Combining CSV files:\n",
    "# Climate_var_name is the name of the column of data\n",
    "Clean_Combine_Location_data_4.clean_comb(data_col_name,list_of_locations) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QTOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar\n",
      "Saving location: Walgett\n",
      "Saving location: Coonamble\n",
      "Saving location: Warren\n",
      "Saving location: Nyngan\n",
      "Saving location: Gilgandra\n",
      "Saving location: Narrabri\n",
      "Saving location: Tamworth\n",
      "Saving location: Coonabarabran\n",
      "Saving location: Mittagong\n",
      "Saving location: Bowral\n",
      "Saving location: Bundanoon\n",
      "Saving location: Robertson\n",
      "Saving location: Moss Vale\n",
      "Saving location: Pilliga\n",
      "Saving location: Cobargo\n",
      "Saving location: Bega\n",
      "Saving location: Wentworth\n",
      "Saving location: Finley\n",
      "Saving location: Deniliquin\n",
      "Saving location: Pooncarie\n",
      "Saving location: Menindee\n",
      "Saving location: Broken Hill\n",
      "Saving location: Bredbo\n",
      "Saving location: Hay\n",
      "Saving location: Coleambally\n",
      "Saving location: Griffith\n",
      "Saving location: Wagga Wagga\n",
      "Saving location: Forbes\n",
      "Saving location: Oxley\n",
      "Saving location: Condobolin\n",
      "Saving location: Cowra\n",
      "Saving location: Blayney\n",
      "Saving location: Carcoar\n",
      "Saving location: Canowindra\n",
      "Saving location: Narromine\n",
      "Saving location: Orange\n",
      "Saving location: Bathurst\n",
      "Saving location: Dubbo\n",
      "Saving location: Mudgee\n",
      "Saving location: Gulgong\n",
      "Saving location: Gunnedah\n",
      "Saving location: Moree\n",
      "Saving location: Uralla\n",
      "Saving location: Goondiwindi\n",
      "Saving location: Tenterfield\n",
      "Saving location: Glen Innes\n",
      "Saving location: Mungindi\n",
      "Saving location: Ashford\n",
      "Saving location: Bonshaw\n",
      "Saving location: Bourke\n",
      "Saving location: Wilcannia\n",
      "Saving location: Collarenebri\n",
      "Saving location: Brewarrina\n",
      "Saving location: Angledool\n",
      "Saving location: Gongolgon\n",
      "Saving location: Tibooburra\n",
      "Saving location: Packsaddle\n",
      "Saving location: Byrock\n",
      "Saving location: Eden\n",
      "Saving location: Bemboka\n",
      "Saving location: Brogo\n",
      "Saving location: Bermagui\n",
      "Saving location: Casino\n",
      "Saving location: Bonalbo\n",
      "Saving location: Scone\n",
      "Saving location: Murrurundi\n",
      "Saving location: Singleton\n",
      "Saving location: Smithtown\n",
      "Saving location: Tocal\n",
      "Saving location: Grafton\n",
      "Saving location: Nowra\n",
      "Saving location: Ulladulla\n",
      "Saving location: Goulburn\n",
      "Saving location: Port Macquarie\n",
      "Saving location: Boggabilla\n",
      "Saving location: Taree\n",
      "Saving location: Raymond Terrace\n",
      "Saving location: Bogan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sy6sh\\Anaconda3\\envs\\Honours_2022\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:953: UserWarning: Warning: converting a masked element to nan.\n",
      "  values[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Wellington\n",
      "Saving location: Cobar \n",
      "Saving location: Dungog\n",
      "Saving location: Inglewood\n"
     ]
    }
   ],
   "source": [
    "#Extract Loc\n",
    "row = 1\n",
    "data_col_name = 'Qtot' #name of column\n",
    "for row in NDVI_loc_file_df.itertuples():\n",
    "    location = row.Category #dloc[row]\n",
    "    d_lat = float(row.Latitude)\n",
    "    d_lon = float(row.Longitude)\n",
    "    Extract_AWRA_data_code_6_28July2022.extract_var_from_netcdf('qtot_Actual_month',location,d_lat,d_lon,data_col_name)\n",
    "\n",
    "#Combining CSV files:\n",
    "# Climate_var_name is the name of the column of data\n",
    "Clean_Combine_Location_data_4.clean_comb(data_col_name,list_of_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar\n",
      "Saving location: Walgett\n",
      "Saving location: Coonamble\n",
      "Saving location: Warren\n",
      "Saving location: Nyngan\n",
      "Saving location: Gilgandra\n",
      "Saving location: Narrabri\n",
      "Saving location: Tamworth\n",
      "Saving location: Coonabarabran\n",
      "Saving location: Mittagong\n",
      "Saving location: Bowral\n",
      "Saving location: Bundanoon\n",
      "Saving location: Robertson\n",
      "Saving location: Moss Vale\n",
      "Saving location: Pilliga\n",
      "Saving location: Cobargo\n",
      "Saving location: Bega\n",
      "Saving location: Wentworth\n",
      "Saving location: Finley\n",
      "Saving location: Deniliquin\n",
      "Saving location: Pooncarie\n",
      "Saving location: Menindee\n",
      "Saving location: Broken Hill\n",
      "Saving location: Bredbo\n",
      "Saving location: Hay\n",
      "Saving location: Coleambally\n",
      "Saving location: Griffith\n",
      "Saving location: Wagga Wagga\n",
      "Saving location: Forbes\n",
      "Saving location: Oxley\n",
      "Saving location: Condobolin\n",
      "Saving location: Cowra\n",
      "Saving location: Blayney\n",
      "Saving location: Carcoar\n",
      "Saving location: Canowindra\n",
      "Saving location: Narromine\n",
      "Saving location: Orange\n",
      "Saving location: Bathurst\n",
      "Saving location: Dubbo\n",
      "Saving location: Mudgee\n",
      "Saving location: Gulgong\n",
      "Saving location: Gunnedah\n",
      "Saving location: Moree\n",
      "Saving location: Uralla\n",
      "Saving location: Goondiwindi\n",
      "Saving location: Tenterfield\n",
      "Saving location: Glen Innes\n",
      "Saving location: Mungindi\n",
      "Saving location: Ashford\n",
      "Saving location: Bonshaw\n",
      "Saving location: Bourke\n",
      "Saving location: Wilcannia\n",
      "Saving location: Collarenebri\n",
      "Saving location: Brewarrina\n",
      "Saving location: Angledool\n",
      "Saving location: Gongolgon\n",
      "Saving location: Tibooburra\n",
      "Saving location: Packsaddle\n",
      "Saving location: Byrock\n",
      "Saving location: Eden\n",
      "Saving location: Bemboka\n",
      "Saving location: Brogo\n",
      "Saving location: Bermagui\n",
      "Saving location: Casino\n",
      "Saving location: Bonalbo\n",
      "Saving location: Scone\n",
      "Saving location: Murrurundi\n",
      "Saving location: Singleton\n",
      "Saving location: Smithtown\n",
      "Saving location: Tocal\n",
      "Saving location: Grafton\n",
      "Saving location: Nowra\n",
      "Saving location: Ulladulla\n",
      "Saving location: Goulburn\n",
      "Saving location: Port Macquarie\n",
      "Saving location: Boggabilla\n",
      "Saving location: Taree\n",
      "Saving location: Raymond Terrace\n",
      "Saving location: Bogan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sy6sh\\Anaconda3\\envs\\Honours_2022\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:953: UserWarning: Warning: converting a masked element to nan.\n",
      "  values[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Wellington\n",
      "Saving location: Cobar \n",
      "Saving location: Dungog\n",
      "Saving location: Inglewood\n"
     ]
    }
   ],
   "source": [
    "#Extract Loc\n",
    "row = 1\n",
    "data_col_name = 'Soil_M_root_zone' #name of column\n",
    "for row in NDVI_loc_file_df.itertuples():\n",
    "    location = row.Category #dloc[row]\n",
    "    d_lat = float(row.Latitude)\n",
    "    d_lon = float(row.Longitude)\n",
    "    Extract_AWRA_data_code_6_28July2022.extract_var_from_netcdf('sm_pct_Actual_month_root_zone',location,d_lat,d_lon,data_col_name)\n",
    "\n",
    "#Combining CSV files:\n",
    "# Climate_var_name is the name of the column of data\n",
    "Clean_Combine_Location_data_4.clean_comb(data_col_name,list_of_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e_actual_tot_Actual_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar\n",
      "Saving location: Walgett\n",
      "Saving location: Coonamble\n",
      "Saving location: Warren\n",
      "Saving location: Nyngan\n",
      "Saving location: Gilgandra\n",
      "Saving location: Narrabri\n",
      "Saving location: Tamworth\n",
      "Saving location: Coonabarabran\n",
      "Saving location: Mittagong\n",
      "Saving location: Bowral\n",
      "Saving location: Bundanoon\n",
      "Saving location: Robertson\n",
      "Saving location: Moss Vale\n",
      "Saving location: Pilliga\n",
      "Saving location: Cobargo\n",
      "Saving location: Bega\n",
      "Saving location: Wentworth\n",
      "Saving location: Finley\n",
      "Saving location: Deniliquin\n",
      "Saving location: Pooncarie\n",
      "Saving location: Menindee\n",
      "Saving location: Broken Hill\n",
      "Saving location: Bredbo\n",
      "Saving location: Hay\n",
      "Saving location: Coleambally\n",
      "Saving location: Griffith\n",
      "Saving location: Wagga Wagga\n",
      "Saving location: Forbes\n",
      "Saving location: Oxley\n",
      "Saving location: Condobolin\n",
      "Saving location: Cowra\n",
      "Saving location: Blayney\n",
      "Saving location: Carcoar\n",
      "Saving location: Canowindra\n",
      "Saving location: Narromine\n",
      "Saving location: Orange\n",
      "Saving location: Bathurst\n",
      "Saving location: Dubbo\n",
      "Saving location: Mudgee\n",
      "Saving location: Gulgong\n",
      "Saving location: Gunnedah\n",
      "Saving location: Moree\n",
      "Saving location: Uralla\n",
      "Saving location: Goondiwindi\n",
      "Saving location: Tenterfield\n",
      "Saving location: Glen Innes\n",
      "Saving location: Mungindi\n",
      "Saving location: Ashford\n",
      "Saving location: Bonshaw\n",
      "Saving location: Bourke\n",
      "Saving location: Wilcannia\n",
      "Saving location: Collarenebri\n",
      "Saving location: Brewarrina\n",
      "Saving location: Angledool\n",
      "Saving location: Gongolgon\n",
      "Saving location: Tibooburra\n",
      "Saving location: Packsaddle\n",
      "Saving location: Byrock\n",
      "Saving location: Eden\n",
      "Saving location: Bemboka\n",
      "Saving location: Brogo\n",
      "Saving location: Bermagui\n",
      "Saving location: Casino\n",
      "Saving location: Bonalbo\n",
      "Saving location: Scone\n",
      "Saving location: Murrurundi\n",
      "Saving location: Singleton\n",
      "Saving location: Smithtown\n",
      "Saving location: Tocal\n",
      "Saving location: Grafton\n",
      "Saving location: Nowra\n",
      "Saving location: Ulladulla\n",
      "Saving location: Goulburn\n",
      "Saving location: Port Macquarie\n",
      "Saving location: Boggabilla\n",
      "Saving location: Taree\n",
      "Saving location: Raymond Terrace\n",
      "Saving location: Bogan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sy6sh\\Anaconda3\\envs\\Honours_2022\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:953: UserWarning: Warning: converting a masked element to nan.\n",
      "  values[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Wellington\n",
      "Saving location: Cobar \n",
      "Saving location: Dungog\n",
      "Saving location: Inglewood\n"
     ]
    }
   ],
   "source": [
    "#Extract Loc\n",
    "row = 1\n",
    "data_col_name = 'E_Actual' #name of column\n",
    "for row in NDVI_loc_file_df.itertuples():\n",
    "    location = row.Category #dloc[row]\n",
    "    d_lat = float(row.Latitude)\n",
    "    d_lon = float(row.Longitude)\n",
    "    Extract_AWRA_data_code_6_28July2022.extract_var_from_netcdf('e_actual_tot_Actual_month',location,d_lat,d_lon,data_col_name)\n",
    "\n",
    "#Combining CSV files:\n",
    "# Climate_var_name is the name of the column of data\n",
    "Clean_Combine_Location_data_4.clean_comb(data_col_name,list_of_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep drainage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar\n",
      "Saving location: Walgett\n",
      "Saving location: Coonamble\n",
      "Saving location: Warren\n",
      "Saving location: Nyngan\n",
      "Saving location: Gilgandra\n",
      "Saving location: Narrabri\n",
      "Saving location: Tamworth\n",
      "Saving location: Coonabarabran\n",
      "Saving location: Mittagong\n",
      "Saving location: Bowral\n",
      "Saving location: Bundanoon\n",
      "Saving location: Robertson\n",
      "Saving location: Moss Vale\n",
      "Saving location: Pilliga\n",
      "Saving location: Cobargo\n",
      "Saving location: Bega\n",
      "Saving location: Wentworth\n",
      "Saving location: Finley\n",
      "Saving location: Deniliquin\n",
      "Saving location: Pooncarie\n",
      "Saving location: Menindee\n",
      "Saving location: Broken Hill\n",
      "Saving location: Bredbo\n",
      "Saving location: Hay\n",
      "Saving location: Coleambally\n",
      "Saving location: Griffith\n",
      "Saving location: Wagga Wagga\n",
      "Saving location: Forbes\n",
      "Saving location: Oxley\n",
      "Saving location: Condobolin\n",
      "Saving location: Cowra\n",
      "Saving location: Blayney\n",
      "Saving location: Carcoar\n",
      "Saving location: Canowindra\n",
      "Saving location: Narromine\n",
      "Saving location: Orange\n",
      "Saving location: Bathurst\n",
      "Saving location: Dubbo\n",
      "Saving location: Mudgee\n",
      "Saving location: Gulgong\n",
      "Saving location: Gunnedah\n",
      "Saving location: Moree\n",
      "Saving location: Uralla\n",
      "Saving location: Goondiwindi\n",
      "Saving location: Tenterfield\n",
      "Saving location: Glen Innes\n",
      "Saving location: Mungindi\n",
      "Saving location: Ashford\n",
      "Saving location: Bonshaw\n",
      "Saving location: Bourke\n",
      "Saving location: Wilcannia\n",
      "Saving location: Collarenebri\n",
      "Saving location: Brewarrina\n",
      "Saving location: Angledool\n",
      "Saving location: Gongolgon\n",
      "Saving location: Tibooburra\n",
      "Saving location: Packsaddle\n",
      "Saving location: Byrock\n",
      "Saving location: Eden\n",
      "Saving location: Bemboka\n",
      "Saving location: Brogo\n",
      "Saving location: Bermagui\n",
      "Saving location: Casino\n",
      "Saving location: Bonalbo\n",
      "Saving location: Scone\n",
      "Saving location: Murrurundi\n",
      "Saving location: Singleton\n",
      "Saving location: Smithtown\n",
      "Saving location: Tocal\n",
      "Saving location: Grafton\n",
      "Saving location: Nowra\n",
      "Saving location: Ulladulla\n",
      "Saving location: Goulburn\n",
      "Saving location: Port Macquarie\n",
      "Saving location: Boggabilla\n",
      "Saving location: Taree\n",
      "Saving location: Raymond Terrace\n",
      "Saving location: Bogan\n",
      "Saving location: Wellington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sy6sh\\Anaconda3\\envs\\Honours_2022\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:953: UserWarning: Warning: converting a masked element to nan.\n",
      "  values[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar \n",
      "Saving location: Dungog\n",
      "Saving location: Inglewood\n"
     ]
    }
   ],
   "source": [
    "#Extract Loc\n",
    "row = 1\n",
    "data_col_name = 'Deep_Drainage' #name of column\n",
    "for row in NDVI_loc_file_df.itertuples():\n",
    "    location = row.Category #dloc[row]\n",
    "    d_lat = float(row.Latitude)\n",
    "    d_lon = float(row.Longitude)\n",
    "    Extract_AWRA_data_code_6_28July2022.extract_var_from_netcdf('deep_drainage_Actual_month',location,d_lat,d_lon,data_col_name)\n",
    "\n",
    "#Combining CSV files:\n",
    "# Climate_var_name is the name of the column of data\n",
    "Clean_Combine_Location_data_4.clean_comb(data_col_name,list_of_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Cobar\n",
      "Saving location: Walgett\n",
      "Saving location: Coonamble\n",
      "Saving location: Warren\n",
      "Saving location: Nyngan\n",
      "Saving location: Gilgandra\n",
      "Saving location: Narrabri\n",
      "Saving location: Tamworth\n",
      "Saving location: Coonabarabran\n",
      "Saving location: Mittagong\n",
      "Saving location: Bowral\n",
      "Saving location: Bundanoon\n",
      "Saving location: Robertson\n",
      "Saving location: Moss Vale\n",
      "Saving location: Pilliga\n",
      "Saving location: Cobargo\n",
      "Saving location: Bega\n",
      "Saving location: Wentworth\n",
      "Saving location: Finley\n",
      "Saving location: Deniliquin\n",
      "Saving location: Pooncarie\n",
      "Saving location: Menindee\n",
      "Saving location: Broken Hill\n",
      "Saving location: Bredbo\n",
      "Saving location: Hay\n",
      "Saving location: Coleambally\n",
      "Saving location: Griffith\n",
      "Saving location: Wagga Wagga\n",
      "Saving location: Forbes\n",
      "Saving location: Oxley\n",
      "Saving location: Condobolin\n",
      "Saving location: Cowra\n",
      "Saving location: Blayney\n",
      "Saving location: Carcoar\n",
      "Saving location: Canowindra\n",
      "Saving location: Narromine\n",
      "Saving location: Orange\n",
      "Saving location: Bathurst\n",
      "Saving location: Dubbo\n",
      "Saving location: Mudgee\n",
      "Saving location: Gulgong\n",
      "Saving location: Gunnedah\n",
      "Saving location: Moree\n",
      "Saving location: Uralla\n",
      "Saving location: Goondiwindi\n",
      "Saving location: Tenterfield\n",
      "Saving location: Glen Innes\n",
      "Saving location: Mungindi\n",
      "Saving location: Ashford\n",
      "Saving location: Bonshaw\n",
      "Saving location: Bourke\n",
      "Saving location: Wilcannia\n",
      "Saving location: Collarenebri\n",
      "Saving location: Brewarrina\n",
      "Saving location: Angledool\n",
      "Saving location: Gongolgon\n",
      "Saving location: Tibooburra\n",
      "Saving location: Packsaddle\n",
      "Saving location: Byrock\n",
      "Saving location: Eden\n",
      "Saving location: Bemboka\n",
      "Saving location: Brogo\n",
      "Saving location: Bermagui\n",
      "Saving location: Casino\n",
      "Saving location: Bonalbo\n",
      "Saving location: Scone\n",
      "Saving location: Murrurundi\n",
      "Saving location: Singleton\n",
      "Saving location: Smithtown\n",
      "Saving location: Tocal\n",
      "Saving location: Grafton\n",
      "Saving location: Nowra\n",
      "Saving location: Ulladulla\n",
      "Saving location: Goulburn\n",
      "Saving location: Port Macquarie\n",
      "Saving location: Boggabilla\n",
      "Saving location: Taree\n",
      "Saving location: Raymond Terrace\n",
      "Saving location: Bogan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sy6sh\\Anaconda3\\envs\\Honours_2022\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:953: UserWarning: Warning: converting a masked element to nan.\n",
      "  values[indexer] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving location: Wellington\n",
      "Saving location: Cobar \n",
      "Saving location: Dungog\n",
      "Saving location: Inglewood\n"
     ]
    }
   ],
   "source": [
    "#Extract Loc\n",
    "row = 1\n",
    "data_col_name = 'Rainfall' #name of column\n",
    "for row in NDVI_loc_file_df.itertuples():\n",
    "    location = row.Category #dloc[row]\n",
    "    d_lat = float(row.Latitude)\n",
    "    d_lon = float(row.Longitude)\n",
    "    Extract_AWRA_data_code_6_28July2022.extract_var_from_netcdf('rain_day_Actual_month',location,d_lat,d_lon,data_col_name)\n",
    "\n",
    "#Combining CSV files:\n",
    "# Climate_var_name is the name of the column of data\n",
    "Clean_Combine_Location_data_4.clean_comb(data_col_name,list_of_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to combine them into the drought db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_drain_df = pd.read_csv('All_Location_Deep_Drainage_test2022_07_29_21_07.csv', encoding = 'unicode_escape')\n",
    "E_tot_df = pd.read_csv('All_Location_E_Actual_test2022_07_29_21_07.csv', encoding = 'unicode_escape')\n",
    "PET_df = pd.read_csv('All_Location_PET_Actual_test2022_07_29_21_12.csv', encoding = 'unicode_escape')\n",
    "Qtot_df = pd.read_csv('All_Location_Qtot_test2022_07_29_21_06.csv', encoding = 'unicode_escape')\n",
    "sm_df = pd.read_csv('All_Location_Soil_M_root_zone_test2022_07_29_21_06.csv', encoding = 'unicode_escape')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df = pd.read_csv('All_Location_Rainfall_test2022_07_29_21_32.csv', encoding = 'unicode_escape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining database and data tables according to Year,Month and Location. \n",
    "clim_var_4 = []\n",
    "clim_var_5 = []\n",
    "clim_var_6 = []\n",
    "clim_var_7 = []\n",
    "clim_var_8 = []\n",
    "row = 1\n",
    "\n",
    "dd_name = 'Deep_Drainage'\n",
    "pet_name = 'PET_Actual'\n",
    "e_name = 'E_Actual'\n",
    "sm_name = 'Soil_M_root_zone'\n",
    "qtot_name = 'Qtot'\n",
    "#For NDVI\n",
    "for row in drought_db.itertuples():\n",
    "    time = row.Year_Month\n",
    "    loca = row.Location\n",
    "    # print(row)\n",
    "    clim_var_4.append(float((deep_drain_df.loc[(deep_drain_df['Year_Month']== time) & (deep_drain_df['Location']== loca)][dd_name].values)))\n",
    "    clim_var_5.append(float((PET_df.loc[(PET_df['Year_Month']== time) & (PET_df['Location']== loca)][pet_name].values)))\n",
    "    clim_var_6.append(float((E_tot_df.loc[(E_tot_df['Year_Month']== time) & (E_tot_df['Location']== loca)][e_name].values)))\n",
    "    clim_var_7.append(float((sm_df.loc[(sm_df['Year_Month']== time) & (sm_df['Location']== loca)][sm_name].values)))\n",
    "    clim_var_8.append(float((Qtot_df.loc[(Qtot_df['Year_Month']== time) & (Qtot_df['Location']== loca)][qtot_name].values)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missed the rain one: \n",
    "# Combining database and data tables according to Year,Month and Location. \n",
    "clim_var_9 = []\n",
    "row = 1\n",
    "\n",
    "r_name = 'Rainfall'\n",
    "#For NDVI\n",
    "for row in drought_db.itertuples():\n",
    "    time = row.Year_Month\n",
    "    loca = row.Location\n",
    "    # print(row)\n",
    "    clim_var_9.append(float((rain_df.loc[(rain_df['Year_Month']== time) & (rain_df['Location']== loca)][r_name].values)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db[dd_name] = clim_var_4\n",
    "drought_db[pet_name] = clim_var_5\n",
    "drought_db[e_name] = clim_var_6\n",
    "drought_db[sm_name] = clim_var_7\n",
    "drought_db[qtot_name] = clim_var_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db.to_csv('Database_All_AWRA_NDVI_data' + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db[r_name] = clim_var_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db.to_csv('Database_All_AWRA_NDVI_Rain_data' + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now ENSO, IOD and SAMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Mof_data_to_database_21_22Jun2022 file for analysis of the Mof data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Mof data\n",
    "enso_file_name = 'ENSO_Data_`948_to_Mar_2022'\n",
    "iod_file_name = 'IOD_DMI_1870_to_2022_Jan'\n",
    "ipo_tpi_file_name = 'IPO_TPI (from NOAA ERSST V5) filtered_ Standard PSL Format'\n",
    "sami_file_name = 'SAMI_1957_to_2022_Mar'\n",
    "\n",
    "ENSO = pd.read_csv('C:/Users/sy6sh/Documents/A.UNSW_COURSE_FOLDERS/Honours 2022/Coding/MoF and NDVI data/'+ enso_file_name +'.csv', encoding = 'unicode_escape')\n",
    "IOD = pd.read_csv('C:/Users/sy6sh/Documents/A.UNSW_COURSE_FOLDERS/Honours 2022/Coding/MoF and NDVI data/' + iod_file_name + '.csv', encoding = 'unicode_escape')\n",
    "IPO_TPI = pd.read_csv('C:/Users/sy6sh/Documents/A.UNSW_COURSE_FOLDERS/Honours 2022/Coding/MoF and NDVI data/' + ipo_tpi_file_name + '.csv', encoding = 'unicode_escape')\n",
    "SAMI = pd.read_csv('C:/Users/sy6sh/Documents/A.UNSW_COURSE_FOLDERS/Honours 2022/Coding/MoF and NDVI data/' + sami_file_name + '.csv', encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSO.columns = ['Year','January','February','March','April','May','June','July', 'August','September','October','November','December']\n",
    "IOD.columns = ['Year','January','February','March','April','May','June','July', 'August','September','October','November','December']\n",
    "IPO_TPI.columns = ['Year','January','February','March','April','May','June','July', 'August','September','October','November','December']\n",
    "IPO_TPI.replace(-99.0,'NaN',inplace = True)\n",
    "SAMI.columns = ['Year','January','February','March','April','May','June','July', 'August','September','October','November','December']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there were a few months in the database that were half written I have to get the df again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name_2 = 'Database_All_AWRA_NDVI_Rain_data2022_07_29_21_35'\n",
    "# Read in database\n",
    "drought_db_2 = pd.read_csv(database_name_2 + '.csv', encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Combining database and data tables according to Year,Month. \n",
    "clim_var_10 = []\n",
    "clim_var_11 = []\n",
    "clim_var_12 = []\n",
    "clim_var_13 = []\n",
    "\n",
    "row = 1\n",
    "\n",
    "for row in drought_db_2.itertuples():\n",
    "    year = row.Year\n",
    "    mth = row.Month\n",
    "    clim_var_10.append(float(ENSO.loc[(ENSO['Year']== year), mth]))\n",
    "    clim_var_11.append(float(IOD.loc[(IOD['Year']== year), mth]))\n",
    "    clim_var_12.append(float(IPO_TPI.loc[(IPO_TPI['Year']== year), mth]))\n",
    "    clim_var_13.append(float(SAMI.loc[(SAMI['Year']== year), mth]))\n",
    "\n",
    "drought_db['ENSO'] = clim_var_10\n",
    "drought_db['IOD'] = clim_var_11\n",
    "drought_db['IPO_TPI'] = clim_var_12\n",
    "drought_db['SAMI'] = clim_var_13\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_db.to_csv('Database_All_AWRA_NDVI_Rain_MOF_data' + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including Precipitation_acc_3 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Combine_Database_Loc_data_2.combine_data('rain_acc3M', 'P_acc_3M' ,'Database_All_AWRA_NDVI_Rain_MOF_data2022_07_29_22_02')\n",
    "# Error:TypeError: only size-1 arrays can be converted to Python scalars\n",
    "\n",
    "prec_3m_df = pd.read_csv('rain_acc3M.csv', encoding = 'unicode_escape')\n",
    "prec_3m_df.drop(['Year','Month','Latitude'], axis=1, inplace = True)\n",
    "\n",
    "# This is the database before checks and removing the -3000 NDVI and EVI. \n",
    "drought_database = pd.read_csv('Database_All_AWRA_NDVI_Rain_MOF_data2022_07_29_22_02.csv', encoding = 'unicode_escape')\n",
    "\n",
    "# Set up code to merge:\n",
    "clim_var = []\n",
    "row = 1\n",
    "clim_name = 'P_acc_3M' \n",
    "\n",
    "#For NDVI\n",
    "for row in drought_database.itertuples():\n",
    "    time_a = row.Year_Month\n",
    "    loca = row.Location\n",
    "    lona = row.Longitude\n",
    "    # print(row)\n",
    "    func = ((prec_3m_df.loc[(prec_3m_df['Year_Month']== time_a) & (prec_3m_df['Location']== loca) & (prec_3m_df['Longitude']== lona)][clim_name]))\n",
    "    clim_var.append(float(func.values))\n",
    "    # When the 'float' is removed then it works but the input are [90.29] and things like this. \n",
    "    # Error with float is TypeError: only size-1 arrays can be converted to Python scalars\n",
    "    # https://stackoverflow.com/questions/36680402/typeerror-only-length-1-arrays-can-be-converted-to-python-scalars-while-plot-sh\n",
    "    # np.vectorize does not work. \n",
    "    # print(clim_var) # I printed it to discover that the code stopped working when it reached wagga wagga as it had two values. \n",
    "drought_database[clim_name] = clim_var\n",
    "\n",
    "#Saving the file\n",
    "drought_database.to_csv('Database_All_AWRA_NDVI_MOf_and_3MPrecip_data' + str(datetime.now().strftime('%Y_%m_%d_%H_%M')) +'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Honours_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07839a5161a50ad95f9c2315d909b8e44b3141537b3172f602e0768d5d17d657"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
